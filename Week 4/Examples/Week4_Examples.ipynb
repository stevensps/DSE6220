{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50701995",
   "metadata": {},
   "source": [
    "# Week 4 Examples\n",
    "\n",
    "###  RDD Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2553066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = '--master local[2] pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36286478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b36cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aa4eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract out the sparkcontext from the session\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "188e75c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an RDD of tuples (name,age)\n",
    "dataRDD = sc.parallelize([('Brooke',20),('Denny',31),('Jules',30),('TD',35),('Brooke',25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "713bd14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use map and reduceByKey transformations with their lambda\n",
    "# expressions to aggregate and then compute the average\n",
    "agesRDD = (dataRDD\n",
    "          .map(lambda x: (x[0], (x[1], 1)))\n",
    "          .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "          .map(lambda x: (x[0], x[1][0]/x[1][1]))\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbd650f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Brooke', 22.5), ('Jules', 30.0), ('TD', 35.0), ('Denny', 31.0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agesRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168a9351",
   "metadata": {},
   "source": [
    "### This code tells Spark how to aggregate the keys and compute averages with a string of lambda functions. However, it is cryptic and hard to understand. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5cff7b",
   "metadata": {},
   "source": [
    "### Instead we can use the DataFrame API which is much more user friendly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "832d5a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = spark.createDataFrame([('Brooke',20),('Denny',31),('Jules',30),('TD',35),('Brooke',25)],schema=['name','age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8065a7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|  name|avg(age)|\n",
      "+------+--------+\n",
      "|Brooke|    22.5|\n",
      "| Denny|    31.0|\n",
      "| Jules|    30.0|\n",
      "|    TD|    35.0|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "# Group the same names together, aggregate their ages, and compute an average\n",
    "avg_df = data_df.groupBy(\"name\").agg(avg('age'))\n",
    "# Show the results of the final execution\n",
    "avg_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999428ba",
   "metadata": {},
   "source": [
    "### Two ways of defining a schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fdc975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "schema_a = StructType([StructField('author',StringType(),False),\n",
    "                    StructField(\"title\",StringType(),False),\n",
    "                    StructField('pages',IntegerType(),False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6affc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schmea for our data using DDL\n",
    "schema_b = \"`ID` INT, `First` STRING, `Last` STRING, `URL` STRING, `Published` STRING, `Hits` INT, `Campaigns` ARRAY<STRING>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c5b3a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define schema for our data\n",
    "schema = StructType([\n",
    "   StructField(\"Id\", IntegerType(), False),\n",
    "   StructField(\"First\", StringType(), False),\n",
    "   StructField(\"Last\", StringType(), False),\n",
    "   StructField(\"Url\", StringType(), False),\n",
    "   StructField(\"Published\", StringType(), False),\n",
    "   StructField(\"Hits\", IntegerType(), False),\n",
    "   StructField(\"Campaigns\", ArrayType(StringType()), False)])\n",
    "\n",
    "#create our data\n",
    "data = [[1, \"Jules\", \"Damji\", \"https://tinyurl.1\", \"1/4/2016\", 4535, [\"twitter\", \"LinkedIn\"]],\n",
    "       [2, \"Brooke\",\"Wenig\",\"https://tinyurl.2\", \"5/5/2018\", 8908, [\"twitter\", \"LinkedIn\"]],\n",
    "       [3, \"Denny\", \"Lee\", \"https://tinyurl.3\",\"6/7/2019\",7659, [\"web\", \"twitter\", \"FB\", \"LinkedIn\"]],\n",
    "       [4, \"Tathagata\", \"Das\",\"https://tinyurl.4\", \"5/12/2018\", 10568, [\"twitter\", \"FB\"]],\n",
    "       [5, \"Matei\",\"Zaharia\", \"https://tinyurl.5\", \"5/14/2014\", 40578, [\"web\", \"twitter\", \"FB\", \"LinkedIn\"]],\n",
    "       [6, \"Reynold\", \"Xin\", \"https://tinyurl.6\", \"3/2/2015\", 25568, [\"twitter\", \"LinkedIn\"]]\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be3b721e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blogs_df = spark.createDataFrame(data, schema)\n",
    "# show the DataFrame; it should reflect our table above\n",
    "blogs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dffdbd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = false)\n",
      " |-- First: string (nullable = false)\n",
      " |-- Last: string (nullable = false)\n",
      " |-- Url: string (nullable = false)\n",
      " |-- Published: string (nullable = false)\n",
      " |-- Hits: integer (nullable = false)\n",
      " |-- Campaigns: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# print the schema used by Spark to process the DataFrame\n",
    "print(blogs_df.printSchema())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1058a9",
   "metadata": {},
   "source": [
    "### Columns and expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2b149b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|(Hits * 2)|\n",
      "+----------+\n",
      "|      9070|\n",
      "|     17816|\n",
      "+----------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----------+\n",
      "|(Hits * 2)|\n",
      "+----------+\n",
      "|      9070|\n",
      "|     17816|\n",
      "+----------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----------+\n",
      "|(Hits * 2)|\n",
      "+----------+\n",
      "|      9070|\n",
      "|     17816|\n",
      "+----------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|Big Hitters|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|      false|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|      false|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|      false|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|       true|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|       true|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|       true|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show columns and expressions\n",
    "blogs_df.select(F.expr(\"Hits\") * 2).show(2)\n",
    "blogs_df.select(F.col(\"Hits\") * 2).show(2)\n",
    "blogs_df.select(F.expr(\"Hits * 2\")).show(2)\n",
    "# show heavy hitters\n",
    "blogs_df.withColumn(\"Big Hitters\", (F.expr(\"Hits > 10000\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb982925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sorting by a specific column\n",
    "blogs_df.sort(F.col(\"Id\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe26bd2",
   "metadata": {},
   "source": [
    "### Reading Data from Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4624645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_schema = StructType([StructField('CallNumber', IntegerType(), True),\n",
    "                     StructField('UnitID', StringType(), True),\n",
    "                     StructField('IncidentNumber', IntegerType(), True),\n",
    "                     StructField('CallType', StringType(), True),                  \n",
    "                     StructField('CallDate', StringType(), True),      \n",
    "                     StructField('WatchDate', StringType(), True),\n",
    "                     StructField('CallFinalDisposition', StringType(), True),\n",
    "                     StructField('AvailableDtTm', StringType(), True),\n",
    "                     StructField('Address', StringType(), True),       \n",
    "                     StructField('City', StringType(), True),       \n",
    "                     StructField('Zipcode', IntegerType(), True),       \n",
    "                     StructField('Battalion', StringType(), True),                 \n",
    "                     StructField('StationArea', StringType(), True),       \n",
    "                     StructField('Box', StringType(), True),       \n",
    "                     StructField('OriginalPriority', StringType(), True),       \n",
    "                     StructField('Priority', StringType(), True),       \n",
    "                     StructField('FinalPriority', IntegerType(), True),       \n",
    "                     StructField('ALSUnit', BooleanType(), True),       \n",
    "                     StructField('CallTypeGroup', StringType(), True),\n",
    "                     StructField('NumAlarms', IntegerType(), True),\n",
    "                     StructField('UnitType', StringType(), True),\n",
    "                     StructField('UnitSequenceInCallDispatch', IntegerType(), True),\n",
    "                     StructField('FirePreventionDistrict', StringType(), True),\n",
    "                     StructField('SupervisorDistrict', StringType(), True),\n",
    "                     StructField('Neighborhood', StringType(), True),\n",
    "                     StructField('Location', StringType(), True),\n",
    "                     StructField('RowID', StringType(), True),\n",
    "                     StructField('Delay', FloatType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e90f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the dataframe reader interface to read a CSV file\n",
    "sf_fire_file = \"./data/sf-fire-calls.csv\"\n",
    "fire_df = spark.read.csv(sf_fire_file,header=True, schema=fire_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0237165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|  CallDate| WatchDate|CallFinalDisposition|       AvailableDtTm|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|        Neighborhood|            Location|        RowID|    Delay|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|  20110016|   T13|       2003235|  Structure Fire|01/11/2002|01/10/2002|               Other|01/11/2002 01:51:...|2000 Block of CAL...|  SF|  94109|      B04|         38|3362|               3|       3|            3|  false|         NULL|        1|   TRUCK|                         2|                     4|                 5|     Pacific Heights|(37.7895840679362...|020110016-T13|     2.95|\n",
      "|  20110022|   M17|       2003241|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 03:01:...|0 Block of SILVER...|  SF|  94124|      B10|         42|6495|               3|       3|            3|   true|         NULL|        1|   MEDIC|                         1|                    10|                10|Bayview Hunters P...|(37.7337623673897...|020110022-M17|      4.7|\n",
      "|  20110023|   M41|       2003242|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 02:39:...|MARKET ST/MCALLIS...|  SF|  94102|      B03|         01|1455|               3|       3|            3|   true|         NULL|        1|   MEDIC|                         2|                     3|                 6|          Tenderloin|(37.7811772186856...|020110023-M41|2.4333334|\n",
      "|  20110032|   E11|       2003250|    Vehicle Fire|01/11/2002|01/10/2002|               Other|01/11/2002 04:16:...|APPLETON AV/MISSI...|  SF|  94110|      B06|         32|5626|               3|       3|            3|  false|         NULL|        1|  ENGINE|                         1|                     6|                 9|      Bernal Heights|(37.7388432849018...|020110032-E11|      1.5|\n",
      "|  20110043|   B04|       2003259|          Alarms|01/11/2002|01/10/2002|               Other|01/11/2002 06:01:...|1400 Block of SUT...|  SF|  94109|      B04|         03|3223|               3|       3|            3|  false|         NULL|        1|   CHIEF|                         2|                     4|                 2|    Western Addition|(37.7872890372638...|020110043-B04|3.4833333|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9b96ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f22936",
   "metadata": {},
   "source": [
    "### Saving a DataFrame as a Parquet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a301805",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/new-sf-fire-calls.parquet\"\n",
    "fire_df.write.format('parquet').mode('overwrite').option(\"header\", \"true\").save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835cfea7",
   "metadata": {},
   "source": [
    "### Transformations and Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e63f88",
   "metadata": {},
   "source": [
    "#### Projections\n",
    "A projection is a way to return only the rows matching a certain relational condition by using filters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76cb0dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+--------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType      |\n",
      "+--------------+----------------------+--------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|Structure Fire|\n",
      "|2003250       |01/11/2002 04:16:46 AM|Vehicle Fire  |\n",
      "|2003259       |01/11/2002 06:01:58 AM|Alarms        |\n",
      "|2003279       |01/11/2002 08:03:26 AM|Structure Fire|\n",
      "|2003301       |01/11/2002 09:46:44 AM|Alarms        |\n",
      "+--------------+----------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "few_fire_df = (fire_df\n",
    "              .select(\"IncidentNumber\",\"AvailableDtTm\",'CallType')\n",
    "              .where(F.col(\"CallType\") != \"Medical Incident\"))\n",
    "few_fire_df.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecb88f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DistinctCallTypes|\n",
      "+-----------------+\n",
      "|               30|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Return number of distinct types of calls using countDistinct()\n",
    "(fire_df\n",
    "    .select(\"CallType\")\n",
    "    .where(F.col(\"CallType\").isNotNull())\n",
    "    .agg(F.countDistinct('CallType').alias(\"DistinctCallTypes\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a5a2675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|CallType                     |\n",
      "+-----------------------------+\n",
      "|Elevator / Escalator Rescue  |\n",
      "|Aircraft Emergency           |\n",
      "|Alarms                       |\n",
      "|Odor (Strange / Unknown)     |\n",
      "|Citizen Assist / Service Call|\n",
      "|HazMat                       |\n",
      "|Explosion                    |\n",
      "|Oil Spill                    |\n",
      "|Vehicle Fire                 |\n",
      "|Suspicious Package           |\n",
      "+-----------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter for only distinct non-null Calltypes from all of the rows\n",
    "(fire_df\n",
    "    .select(\"CallType\")\n",
    "    .where(F.col('CallType').isNotNull())\n",
    "    .distinct()\n",
    "    .show(10,False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0de3ff",
   "metadata": {},
   "source": [
    "### Renaming, adding, and dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89dd7f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|ResponseDelayedinMins|\n",
      "+---------------------+\n",
      "|5.35                 |\n",
      "|6.25                 |\n",
      "|5.2                  |\n",
      "|5.6                  |\n",
      "|7.25                 |\n",
      "+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_fire_df= fire_df.withColumnRenamed(\"Delay\",'ResponseDelayedinMins')\n",
    "(new_fire_df\n",
    "     .select('ResponseDelayedinMins')\n",
    "     .where(F.col('ResponseDelayedinMins') > 5)\n",
    "     .show(5,False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e0a517",
   "metadata": {},
   "source": [
    "#### Modifying column contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51be16f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+\n",
      "|IncidentDate       |OnWatchDate        |AvailableDtTS      |\n",
      "+-------------------+-------------------+-------------------+\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 01:51:44|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 03:01:18|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 02:39:50|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 04:16:46|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 06:01:58|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_ts_df = (new_fire_df\n",
    "             .withColumn('IncidentDate',F.to_timestamp(F.col('CallDate'),'MM/DD/yyyy'))\n",
    "             .drop('CallDate')\n",
    "             .withColumn('OnWatchDate',F.to_timestamp(F.col('WatchDate'),'MM/DD/yyyy'))\n",
    "             .drop('WatchDate')\n",
    "             .withColumn('AvailableDtTS',F.to_timestamp(F.col('AvailableDtTm'),'MM/DD/yyyy hh:mm:ss a'))\n",
    "             .drop('AvailableDtTm')\n",
    "             )\n",
    "\n",
    "(fire_ts_df\n",
    "    .select('IncidentDate','OnWatchDate','AvailableDtTS')\n",
    "    .show(5,False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945a4b52",
   "metadata": {},
   "source": [
    "#### Date time functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d47831e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|year(IncidentDate)|\n",
      "+------------------+\n",
      "|              NULL|\n",
      "|              2001|\n",
      "|              2002|\n",
      "|              2003|\n",
      "|              2004|\n",
      "|              2005|\n",
      "|              2006|\n",
      "|              2007|\n",
      "|              2008|\n",
      "|              2009|\n",
      "|              2010|\n",
      "|              2011|\n",
      "|              2012|\n",
      "|              2013|\n",
      "|              2014|\n",
      "|              2015|\n",
      "|              2016|\n",
      "|              2017|\n",
      "|              2018|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    "     .select(F.year('IncidentDate'))\n",
    "     .distinct()\n",
    "     .orderBy(F.year('IncidentDate'))\n",
    "     .show()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454f069c",
   "metadata": {},
   "source": [
    "### Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76df8d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+------+\n",
      "|CallType                       |count |\n",
      "+-------------------------------+------+\n",
      "|Medical Incident               |113794|\n",
      "|Structure Fire                 |23319 |\n",
      "|Alarms                         |19406 |\n",
      "|Traffic Collision              |7013  |\n",
      "|Citizen Assist / Service Call  |2524  |\n",
      "|Other                          |2166  |\n",
      "|Outside Fire                   |2094  |\n",
      "|Vehicle Fire                   |854   |\n",
      "|Gas Leak (Natural and LP Gases)|764   |\n",
      "|Water Rescue                   |755   |\n",
      "+-------------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    "    .select('CallType')\n",
    "    .where(F.col('CallType').isNotNull())\n",
    "    .groupBy('CallType')\n",
    "    .count()\n",
    "    .orderBy('count',ascending=False)\n",
    "    .show(10,truncate=False)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba93b6e4",
   "metadata": {},
   "source": [
    "### Other common DataFrame operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3eddbe5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "|sum(NumAlarms)|avg(ResponseDelayedinMins)|min(ResponseDelayedinMins)|max(ResponseDelayedinMins)|\n",
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "|        176170|         3.892364154521585|               0.016666668|                   1844.55|\n",
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    "     .select(F.sum(\"NumAlarms\"),F.avg(\"ResponseDelayedinMins\"),\n",
    "             F.min('ResponseDelayedinMins'),F.max('ResponseDelayedinMins')           \n",
    "            )\n",
    "     .show()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f4efff",
   "metadata": {},
   "source": [
    "### UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e5c1ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import LongType\n",
    "def cubed(s):\n",
    "    return s * s * s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09d26a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.cubed(s)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register the UDF\n",
    "spark.udf.register('cubed',cubed,LongType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1177f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Temp View\n",
    "spark.range(1,9).createOrReplaceTempView('udf_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd95a2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|id_cubed|\n",
      "+---+--------+\n",
      "|  1|       1|\n",
      "|  2|       8|\n",
      "|  3|      27|\n",
      "|  4|      64|\n",
      "|  5|     125|\n",
      "|  6|     216|\n",
      "|  7|     343|\n",
      "|  8|     512|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the cubed UDF\n",
    "spark.sql('SELECT id, cubed(id) AS id_cubed FROM udf_test').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63db9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd5b630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
